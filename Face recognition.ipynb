{"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport cv2\nimport csv\nimport random\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch.utils.data as Data\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import Dataset, DataLoader\nfrom pandas import read_csv\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"execution":{"iopub.status.busy":"2022-12-22T05:52:18.760818Z","iopub.execute_input":"2022-12-22T05:52:18.761160Z","iopub.status.idle":"2022-12-22T05:52:18.767712Z","shell.execute_reply.started":"2022-12-22T05:52:18.761131Z","shell.execute_reply":"2022-12-22T05:52:18.766618Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class mydataset(Dataset):    \n    def __init__(self, imgname, label,transform=None):\n        self.transform = transform        \n        self.images =  imgname        \n        self.labels = label \n    \n    def __len__(self):        \n        # 返回数据集的数据数量        \n        return len(self.images)  \n\n    def __getitem__(self, index):        \n        img_path = self.images[index]        \n        label = self.labels[index]        \n        img = cv2.imread(img_path)       \n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        \n        img = Image.fromarray(img)        \n        if self.transform:            \n            img = self.transform(img)        \n        return img,label\n#获取图片路径    \ndef getImgpath(path, name):    \n        return path+\"/\"+str(name)+\".jpg\"\n#数据预处\ndata_transfrom = transforms.Compose([\n    transforms.Resize((200,200)),\n    transforms.ToTensor(),\n    \n])\n    \n#将数据划分为训练集和测试集\ntraindata_path = \"/kaggle/input/trainphotos/train/\"\ntestdata_path = \"/kaggle/input/testphotos/test/\"\n\ntrain_csv= '/kaggle/input/traincsv/train.csv'\ntest_csv= '/kaggle/input/testcsv/test.csv'\n\ntrain_data=pd.read_csv(train_csv)\ntest_data=pd.read_csv(test_csv)\n\ntrain_img_id = train_data.iloc[:,0].values    \ntest_img_id = test_data.iloc[:,0].values\n\ntrain_label = train_data.iloc[:,1].values\ntest_label = test_data.iloc[:,1].values\n    \ntrain_img_path = [getImgpath(name=name,path=traindata_path) for name in train_img_id]\ntest_img_path = [getImgpath(name=name,path=testdata_path) for name in test_img_id]\n# 通过GetLoader将数据进行加载，返回Dataset对象，包含data和labels\ntrain_data = mydataset(train_img_path, train_label, data_transfrom)\ntest_data = mydataset(test_img_path, test_label, data_transfrom)\n#使用DataLoader加载并设置batchsize\ntrain_loader = DataLoader(train_data, batch_size=64, drop_last=True,shuffle = True)\ntest_loader = DataLoader(test_data, batch_size=64, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-22T05:52:18.773893Z","iopub.execute_input":"2022-12-22T05:52:18.774163Z","iopub.status.idle":"2022-12-22T05:52:18.816252Z","shell.execute_reply.started":"2022-12-22T05:52:18.774138Z","shell.execute_reply":"2022-12-22T05:52:18.815351Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Residual(nn.Module):\n    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1): \n        super(Residual, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)  # 定义第一个卷积块\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 定义第二个卷积块\n\n        # 定义1x1卷积块\n        if use_1x1conv:\n            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n        else:\n            self.conv3 = None\n\n        # Batch归一化\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n    # 定义前向传播路径\n    def forward(self, x):\n        y = nn.functional.relu(self.bn1(self.conv1(x)))\n        y = self.bn2(self.conv2(y))\n        if self.conv3:\n            x = self.conv3(x)\n\n        return nn.functional.relu(y + x)\n\ndef resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n    if first_block:\n        assert in_channels == out_channels  # 第一个模块的通道数同输入通道数一致\n    blk = []\n    for i in range(num_residuals):\n        if i == 0 and not first_block:\n            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n        else:\n            blk.append(Residual(out_channels, out_channels))\n    return nn.Sequential(*blk)\n\n\n# 定义一个全局平均池化层\nclass GlobalAvgPool2d(nn.Module):\n    def __init__(self):\n        super(GlobalAvgPool2d, self).__init__()\n\n    def forward(self, x):\n        return nn.functional.avg_pool2d(x, kernel_size=x.size()[2:])  # 池化窗口形状等于输入图像的形状\n\n# 定义ResNet网络结构\ndef ResNet():\n    net = nn.Sequential(\n        nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n        nn.BatchNorm2d(64),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n\n    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n    net.add_module(\"global_avg_pool\", GlobalAvgPool2d())  # GlobalAvgPool2d的输出: (Batch, 512, 1, 1)\n    net.add_module(\"fc\", nn.Sequential(nn.Flatten(), nn.Linear(512, 10)))\n\n    return net\ndevice = torch.device(\"cuda\")\nmodel = ResNet().to(device)\nprint(model)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-22T05:52:18.818024Z","iopub.execute_input":"2022-12-22T05:52:18.818276Z","iopub.status.idle":"2022-12-22T05:52:18.942570Z","shell.execute_reply.started":"2022-12-22T05:52:18.818253Z","shell.execute_reply":"2022-12-22T05:52:18.941439Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (resnet_block1): Sequential(\n    (0): Residual(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Residual(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (resnet_block2): Sequential(\n    (0): Residual(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Residual(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (resnet_block3): Sequential(\n    (0): Residual(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Residual(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (resnet_block4): Sequential(\n    (0): Residual(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Residual(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (global_avg_pool): GlobalAvgPool2d()\n  (fc): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"## Specify loss and optimization functions\n\n# specify loss function\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-12-22T05:52:18.943866Z","iopub.execute_input":"2022-12-22T05:52:18.945154Z","iopub.status.idle":"2022-12-22T05:52:18.951001Z","shell.execute_reply.started":"2022-12-22T05:52:18.945112Z","shell.execute_reply":"2022-12-22T05:52:18.949981Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# number of epochs to train the model\nn_epochs = 10  # suggest training between 20-50 epochs\n\nmodel.train() # prep model for training\ndevice = torch.device(\"cuda\")\nfor epoch in range(n_epochs):\n    # monitor training loss\n    train_loss = 0.0\n    for step, (b_x, b_y) in enumerate(train_loader): \n        #----------------------------#\n        #   计算loss并修正权值\n        #----------------------------#   \n        b_x = b_x.to(device)\n        b_y = b_y.to(device)\n        output = model(b_x)\n        loss = criterion(output, b_y) \n        optimizer.zero_grad() \n        loss.backward() \n        optimizer.step() \n        #----------------------------#\n        #   打印\n        #----------------------------#   \n        if (step+1) % 100 == 0:\n            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, n_epochs, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2022-12-22T05:52:18.953516Z","iopub.execute_input":"2022-12-22T05:52:18.954180Z","iopub.status.idle":"2022-12-22T06:02:27.275555Z","shell.execute_reply.started":"2022-12-22T05:52:18.954132Z","shell.execute_reply":"2022-12-22T06:02:27.274440Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.3910\nEpoch [1/10], Loss: 0.4404\nEpoch [2/10], Loss: 0.2753\nEpoch [2/10], Loss: 0.3835\nEpoch [3/10], Loss: 0.2359\nEpoch [3/10], Loss: 0.2031\nEpoch [4/10], Loss: 0.1573\nEpoch [4/10], Loss: 0.1380\nEpoch [5/10], Loss: 0.0910\nEpoch [5/10], Loss: 0.0406\nEpoch [6/10], Loss: 0.1189\nEpoch [6/10], Loss: 0.0997\nEpoch [7/10], Loss: 0.1692\nEpoch [7/10], Loss: 0.0822\nEpoch [8/10], Loss: 0.1138\nEpoch [8/10], Loss: 0.2654\nEpoch [9/10], Loss: 0.0348\nEpoch [9/10], Loss: 0.0452\nEpoch [10/10], Loss: 0.0167\nEpoch [10/10], Loss: 0.1022\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()      #测试模式，关闭正则化\ncorrect = 0\ntotal = 0\ntest_loss = 0\nfor data, target in test_loader:\n    data, target = data.to(device),target.to(device)\n    outputs = model(data)\n    _, predicted = torch.max(outputs, 1)   #返回值和索引\n    total += target.size(0)\n    correct += (predicted == target).sum().item()\n    loss = criterion(outputs, target) \n    test_loss += loss.item()*data.size(0)\n\nprint('测试准确率: {:.4f}'.format(100.0*correct/total))","metadata":{"execution":{"iopub.status.busy":"2022-12-22T06:02:27.279168Z","iopub.execute_input":"2022-12-22T06:02:27.280574Z","iopub.status.idle":"2022-12-22T06:03:26.944142Z","shell.execute_reply.started":"2022-12-22T06:02:27.280532Z","shell.execute_reply":"2022-12-22T06:03:26.943118Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"测试准确率: 84.4758\n","output_type":"stream"}]}]}